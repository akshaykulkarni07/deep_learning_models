{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/akshaykulkarni/flowers/train/'\n",
    "batch_size = 1024\n",
    "tf = transforms.Compose([transforms.Resize((255, 255)),\n",
    "                         transforms.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "\n",
    "data_dir = '/Users/akshaykulkarni/flowers/test/'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-019544deeeed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m255\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_loader' is not defined"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "images = images.view(-1, images.shape[0]).float()\n",
    "print(images.shape)\n",
    "images /= 255\n",
    "labels = labels.float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of different variables\n",
    "# W and dw - (n, 1)\n",
    "# b and db - (1)\n",
    "# images - (n, batch_size)\n",
    "# labels - (batch_size)\n",
    "# out and pred - (1, batch_size)\n",
    "# loss - (1)\n",
    "m = len(train_loader) * batch_size\n",
    "n = 255 * 255 * 3\n",
    "learning_rate = 2\n",
    "W = torch.randn(n, 1).float()\n",
    "b = torch.randn(1).float()\n",
    "num_epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(A, Y):\n",
    "    loss = (-1 / batch_size) * (torch.matmul(torch.log(A), Y) + torch.matmul(torch.log(1 - A), (1 - Y)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return (1 / (1 + torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y):\n",
    "    out = sigmoid(torch.add(torch.matmul(W.t(), x), b))\n",
    "    # size - (1, batch_size)\n",
    "    loss = binary_cross_entropy(out, y)\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(A, Y, X):\n",
    "    Y2 = Y.view(1, Y.shape[0])\n",
    "    dz = A - Y2\n",
    "    dw = torch.matmul(X, dz.t()) / batch_size\n",
    "    db = torch.sum(dz) / batch_size\n",
    "    db = db.reshape([1])\n",
    "    assert(W.shape == dw.shape)\n",
    "    assert(b.shape == db.shape)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch  0  =  1.070543885231018\n",
      "Loss at epoch  20  =  0.6998060941696167\n",
      "Loss at epoch  40  =  0.6980695724487305\n",
      "Loss at epoch  60  =  0.6965532302856445\n",
      "Loss at epoch  80  =  0.6952072381973267\n",
      "Loss at epoch  100  =  0.6939963698387146\n",
      "Loss at epoch  120  =  0.6928946375846863\n",
      "Loss at epoch  140  =  0.6918826103210449\n",
      "Loss at epoch  160  =  0.6909450888633728\n",
      "Loss at epoch  180  =  0.6900707483291626\n",
      "Loss at epoch  200  =  0.6892505884170532\n",
      "Loss at epoch  220  =  0.6884773373603821\n",
      "Loss at epoch  240  =  0.6877448558807373\n",
      "Loss at epoch  260  =  0.6870485544204712\n",
      "Loss at epoch  280  =  0.6863839626312256\n",
      "Loss at epoch  300  =  0.6857475638389587\n",
      "Loss at epoch  320  =  0.6851369142532349\n",
      "Loss at epoch  340  =  0.6845489740371704\n",
      "Loss at epoch  360  =  0.6839815378189087\n",
      "Loss at epoch  380  =  0.6834332346916199\n",
      "Loss at epoch  400  =  0.6829017400741577\n",
      "Loss at epoch  420  =  0.6823862195014954\n",
      "Loss at epoch  440  =  0.6818849444389343\n",
      "Loss at epoch  460  =  0.6813971400260925\n",
      "Loss at epoch  480  =  0.6809215545654297\n",
      "Loss at epoch  500  =  0.680457353591919\n",
      "Loss at epoch  520  =  0.6800039410591125\n",
      "Loss at epoch  540  =  0.6795605421066284\n",
      "Loss at epoch  560  =  0.6791261434555054\n",
      "Loss at epoch  580  =  0.6787007451057434\n",
      "Loss at epoch  600  =  0.6782833933830261\n",
      "Loss at epoch  620  =  0.6778738498687744\n",
      "Loss at epoch  640  =  0.6774716377258301\n",
      "Loss at epoch  660  =  0.6770762801170349\n",
      "Loss at epoch  680  =  0.676687479019165\n",
      "Loss at epoch  700  =  0.6763049960136414\n",
      "Loss at epoch  720  =  0.6759284138679504\n",
      "Loss at epoch  740  =  0.6755573749542236\n",
      "Loss at epoch  760  =  0.6751918792724609\n",
      "Loss at epoch  780  =  0.6748315691947937\n",
      "Loss at epoch  800  =  0.6744760870933533\n",
      "Loss at epoch  820  =  0.6741254329681396\n",
      "Loss at epoch  840  =  0.6737792491912842\n",
      "Loss at epoch  860  =  0.6734374165534973\n",
      "Loss at epoch  880  =  0.6730998754501343\n",
      "Loss at epoch  900  =  0.6727662086486816\n",
      "Loss at epoch  920  =  0.6724364757537842\n",
      "Loss at epoch  940  =  0.6721104979515076\n",
      "Loss at epoch  960  =  0.671788215637207\n",
      "Loss at epoch  980  =  0.6714692115783691\n",
      "Loss at epoch  1000  =  0.6711536049842834\n",
      "Loss at epoch  1020  =  0.6708415150642395\n",
      "Loss at epoch  1040  =  0.6705322265625\n",
      "Loss at epoch  1060  =  0.6702261567115784\n",
      "Loss at epoch  1080  =  0.6699230670928955\n",
      "Loss at epoch  1100  =  0.6696227788925171\n",
      "Loss at epoch  1120  =  0.6693253517150879\n",
      "Loss at epoch  1140  =  0.6690305471420288\n",
      "Loss at epoch  1160  =  0.6687385439872742\n",
      "Loss at epoch  1180  =  0.668448805809021\n",
      "Loss at epoch  1200  =  0.6681616306304932\n",
      "Loss at epoch  1220  =  0.6678770780563354\n",
      "Loss at epoch  1240  =  0.6675947308540344\n",
      "Loss at epoch  1260  =  0.6673145890235901\n",
      "Loss at epoch  1280  =  0.667036771774292\n",
      "Loss at epoch  1300  =  0.666761040687561\n",
      "Loss at epoch  1320  =  0.6664875745773315\n",
      "Loss at epoch  1340  =  0.6662161350250244\n",
      "Loss at epoch  1360  =  0.6659466624259949\n",
      "Loss at epoch  1380  =  0.6656791567802429\n",
      "Loss at epoch  1400  =  0.6654136180877686\n",
      "Loss at epoch  1420  =  0.6651498675346375\n",
      "Loss at epoch  1440  =  0.6648881435394287\n",
      "Loss at epoch  1460  =  0.6646280288696289\n",
      "Loss at epoch  1480  =  0.6643698215484619\n",
      "Loss at epoch  1500  =  0.6641132831573486\n",
      "Loss at epoch  1520  =  0.6638585329055786\n",
      "Loss at epoch  1540  =  0.6636053323745728\n",
      "Loss at epoch  1560  =  0.6633536219596863\n",
      "Loss at epoch  1580  =  0.6631036996841431\n",
      "Loss at epoch  1600  =  0.662855327129364\n",
      "Loss at epoch  1620  =  0.66260826587677\n",
      "Loss at epoch  1640  =  0.6623629331588745\n",
      "Loss at epoch  1660  =  0.6621190905570984\n",
      "Loss at epoch  1680  =  0.6618765592575073\n",
      "Loss at epoch  1700  =  0.6616354584693909\n",
      "Loss at epoch  1720  =  0.6613959074020386\n",
      "Loss at epoch  1740  =  0.661157488822937\n",
      "Loss at epoch  1760  =  0.6609206199645996\n",
      "Loss at epoch  1780  =  0.6606850028038025\n",
      "Loss at epoch  1800  =  0.6604506373405457\n",
      "Loss at epoch  1820  =  0.6602175235748291\n",
      "Loss at epoch  1840  =  0.6599858999252319\n",
      "Loss at epoch  1860  =  0.6597553491592407\n",
      "Loss at epoch  1880  =  0.659525990486145\n",
      "Loss at epoch  1900  =  0.6592978239059448\n",
      "Loss at epoch  1920  =  0.6590708494186401\n",
      "Loss at epoch  1940  =  0.658845067024231\n",
      "Loss at epoch  1960  =  0.6586204171180725\n",
      "Loss at epoch  1980  =  0.6583969593048096\n",
      "Loss at epoch  2000  =  0.6581745743751526\n",
      "Loss at epoch  2020  =  0.6579532027244568\n",
      "Loss at epoch  2040  =  0.6577330827713013\n",
      "Loss at epoch  2060  =  0.6575139760971069\n",
      "Loss at epoch  2080  =  0.657295823097229\n",
      "Loss at epoch  2100  =  0.6570785045623779\n",
      "Loss at epoch  2120  =  0.6568624973297119\n",
      "Loss at epoch  2140  =  0.6566474437713623\n",
      "Loss at epoch  2160  =  0.6564333438873291\n",
      "Loss at epoch  2180  =  0.6562202572822571\n",
      "Loss at epoch  2200  =  0.656008243560791\n",
      "Loss at epoch  2220  =  0.655797004699707\n",
      "Loss at epoch  2240  =  0.655586838722229\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a9510f286897>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m# convert to float and resize images to (n, batch_size) size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-aecbb6f321dc>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# size - (1, batch_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Batch Gradient Descent\n",
    "loss_list = list()\n",
    "for i in range(4000):\n",
    "    # convert to GPU tensors\n",
    "    if torch.cuda.is_available():\n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "        W, b = W.cuda(), b.cuda()\n",
    "\n",
    "    loss, pred = forward(images, labels)\n",
    "    epoch_loss = loss.item()\n",
    "    loss_list.append(loss.item())\n",
    "    dw, db = backward(pred, labels, images)\n",
    "    # updating weights\n",
    "    W = W - (learning_rate * dw)\n",
    "    b = b - (learning_rate * db)\n",
    "    \n",
    "#     print(W)\n",
    "#     print(b)\n",
    "    if i % 20 == 0:\n",
    "        print('Loss at epoch ', i, ' = ', epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy =  tensor(62.0117)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    images = images.cuda()\n",
    "    labels = labels.cuda()\n",
    "    W = W.cuda()\n",
    "    b = b.cuda()\n",
    "    \n",
    "loss, pred = forward(images, labels)\n",
    "pred = (pred >= 0.5)\n",
    "\n",
    "pred = pred.view(pred.shape[1])\n",
    "mismatch = (torch.eq(pred, labels.byte()))\n",
    "acc = torch.sum(mismatch.float())\n",
    "acc = acc * 100 / 1024\n",
    "print('Training accuracy = ', acc)\n",
    "\n",
    "# acc = 0\n",
    "# for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "#     if torch.cuda.is_available():\n",
    "#         images = images.cuda()\n",
    "#         labels = labels.cuda()\n",
    "#         W = W.cuda()\n",
    "#         b = b.cuda()\n",
    "#     labels = labels.float()\n",
    "#     images = images.view(-1, images.shape[0]).float()\n",
    "#     images /= 255\n",
    "\n",
    "#     loss, pred = forward(images, labels)\n",
    "#     pred = (pred >= 0.5)\n",
    "\n",
    "#     pred = pred.view(pred.shape[1])\n",
    "#     mismatch = torch.sum(torch.eq(pred, labels.byte()))\n",
    "#     acc += mismatch.item()\n",
    "\n",
    "# acc /= (len(test_loader) * 32)\n",
    "# print('Validation accuracy = ', acc * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Batch Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of training images -  1376\n",
      "No. of testing images -  96\n"
     ]
    }
   ],
   "source": [
    "data_dir = '/home/ivlabs/users/akshay/flowers/train/'\n",
    "batch_size = 32\n",
    "tf = transforms.Compose([transforms.Resize((255, 255)),\n",
    "                         transforms.RandomHorizontalFlip(p = 0.5),\n",
    "                         transforms.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "\n",
    "data_dir = '/home/ivlabs/users/akshay/flowers/test/'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "\n",
    "print('No. of training images - ', len(train_loader) * batch_size)\n",
    "print('No. of testing images - ', len(test_loader) * batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dimensions of different variables\n",
    "# W and dw - (n, 1)\n",
    "# b and db - (1)\n",
    "# images - (n, batch_size)\n",
    "# labels - (batch_size)\n",
    "# out and pred - (1, batch_size)\n",
    "# loss - (1)\n",
    "m = len(train_loader) * batch_size\n",
    "n = 255 * 255 * 3\n",
    "learning_rate = 1\n",
    "# W = torch.randn(n, 1).float()\n",
    "b = torch.randn(1).float()\n",
    "# Xavier initialization of weights\n",
    "W = torch.empty(n, 1)\n",
    "nn.init.xavier_uniform_(W, gain=nn.init.calculate_gain('sigmoid'))\n",
    "num_epochs = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(A, Y):\n",
    "    loss = (-1 / batch_size) * (torch.matmul(torch.log(A), Y) + torch.matmul(torch.log(1 - A), (1 - Y)))\n",
    "    return loss\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + torch.exp(-x)))\n",
    "\n",
    "def forward(x, y):\n",
    "    out = torch.add(torch.matmul(W.t(), x), b)\n",
    "    out = sigmoid(out)\n",
    "    # size - (1, batch_size)\n",
    "    loss = binary_cross_entropy(out, y)\n",
    "    return loss, out\n",
    "\n",
    "def backward(A, Y, X):\n",
    "    Y2 = Y.view(1, Y.shape[0])\n",
    "    dz = A - Y2\n",
    "    dw = torch.matmul(X, dz.t()) / batch_size\n",
    "    db = torch.sum(dz) / batch_size\n",
    "    db = db.reshape([1])\n",
    "    assert(W.shape == dw.shape)\n",
    "    assert(b.shape == db.shape)\n",
    "    return dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss at epoch  0  =  0.9934323020279408\n",
      "Validation accuracy =  66.66666666666666\n",
      "Loss at epoch  1  =  0.9763908199965954\n",
      "Validation accuracy =  37.5\n",
      "Loss at epoch  2  =  0.964224262163043\n",
      "Validation accuracy =  65.625\n"
     ]
    }
   ],
   "source": [
    "train_acc_list = list()\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "val_acc_list = list()\n",
    "for i in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    DW = torch.zeros(n, 1).float()\n",
    "    DB = torch.zeros(1).float()\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        # convert to GPU tensors\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            W, b = W.cuda(), b.cuda()\n",
    "            DW, DB = DW.cuda(), DB.cuda()\n",
    "\n",
    "        # convert to float and resize images to (n, batch_size) size\n",
    "        labels = labels.float()\n",
    "        images = images.view(-1, images.shape[0]).float()\n",
    "        images /= 255\n",
    "\n",
    "        loss, pred = forward(images, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        dw, db = backward(pred, labels, images)\n",
    "        assert(DW.shape == dw.shape)\n",
    "        assert(DB.shape == db.shape)\n",
    "        DW += dw\n",
    "        DB += db\n",
    "\n",
    "        pred = (pred >= 0.5)\n",
    "        pred = pred.view(pred.shape[1])\n",
    "        mismatch = torch.sum(torch.eq(pred, labels.byte()))\n",
    "        train_acc += mismatch.item()\n",
    "\n",
    "    DB /= len(train_loader)\n",
    "    DW /= len(train_loader)\n",
    "    # updating weights\n",
    "    W = W - (learning_rate * DW)\n",
    "    b = b - (learning_rate * DB)\n",
    "\n",
    "    if i % 25 == 0:\n",
    "        weights_name = 'weights_' + str(i) + '.pt'\n",
    "        bias_name = 'bias_' + str(i) + '.pt'\n",
    "        torch.save(W, weights_name)\n",
    "        torch.save(b, bias_name)\n",
    "#     print(W)\n",
    "#     print(b)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    # print(f'Training Loss at {i} is equal to {epoch_loss}')\n",
    "\n",
    "    train_acc /= (len(train_loader) * batch_size)\n",
    "    train_acc_list.append(train_acc * 100)\n",
    "    # print('Training accuracy at epoch ', i, ' = ', acc * 100)\n",
    "\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    for batch_idx, (images, labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "            W = W.cuda()\n",
    "            b = b.cuda()\n",
    "        labels = labels.float()\n",
    "        images = images.view(-1, images.shape[0]).float()\n",
    "        images /= 255\n",
    "\n",
    "        loss, pred = forward(images, labels)\n",
    "        val_loss += loss.item()\n",
    "        pred = (pred >= 0.5)\n",
    "\n",
    "        pred = pred.view(pred.shape[1])\n",
    "        mismatch = torch.sum(torch.eq(pred, labels.byte()))\n",
    "        val_acc += mismatch.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    # print('Validation Loss at epoch ', i, ' = ', val_loss)\n",
    "\n",
    "    val_acc /= (len(test_loader) * batch_size)\n",
    "    val_acc_list.append(val_acc * 100)\n",
    "    # print('Validation accuracy at epoch ', i, ' = ', val_acc * 100)\n",
    "    print(f'Epoch : [{i} / {num_epochs}] | TL : {train_loss} | TA : {train_acc * 100} | VL : {val_loss} | VA : {val_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "x and y must have same first dimension, but have shapes (50,) and (5000,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ca131e3c56ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_iterations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   3361\u001b[0m                       mplDeprecation)\n\u001b[1;32m   3362\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3363\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3364\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3365\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwashold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/__init__.py\u001b[0m in \u001b[0;36minner\u001b[0;34m(ax, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1865\u001b[0m                         \u001b[0;34m\"the Matplotlib list!)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[0;32m-> 1867\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1526\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_alias_map\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1527\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1528\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1529\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_grab_next_args\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mseg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mseg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex_of\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xy_from_xy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'plot'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_xy_from_xy\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             raise ValueError(\"x and y must have same first dimension, but \"\n\u001b[0;32m--> 242\u001b[0;31m                              \"have shapes {} and {}\".format(x.shape, y.shape))\n\u001b[0m\u001b[1;32m    243\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m             raise ValueError(\"x and y can be no greater than 2-D, but have \"\n",
      "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (50,) and (5000,)"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 380
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = \"train_loss_list_500epochs.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in train_loss_list:\n",
    "        writer.writerow([value])\n",
    "\n",
    "csvfile = \"val_loss_list_500epochs.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in val_loss_list:\n",
    "        writer.writerow([value])\n",
    "\n",
    "csvfile = \"train_acc_list_500epochs.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in train_acc_list:\n",
    "        writer.writerow([value])\n",
    "\n",
    "csvfile = \"val_acc_list_500epochs.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in val_acc_list:\n",
    "        writer.writerow([value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
