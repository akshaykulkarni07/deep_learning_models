{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4.1\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn as nn\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Implementation and Binary Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = '/home/ivlabs/users/akshay/flowers/train'\n",
    "data_dir = '/Users/akshaykulkarni/flowers/train/'\n",
    "batch_size = 1024\n",
    "tf = transforms.Compose([transforms.Resize((255, 255)),\n",
    "                         transforms.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "\n",
    "# data_dir = '/home/ivlabs/users/akshay/flowers/test'\n",
    "data_dir = '/Users/akshaykulkarni/flowers/test/'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading all the images in the single batch and flattening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 3, 255, 255])\n",
      "torch.Size([195075, 1024])\n",
      "torch.Size([1024])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(images.shape)\n",
    "images = images.view(-1, images.shape[0]).float()\n",
    "print(images.shape)\n",
    "images /= 255\n",
    "labels = labels.float()\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing the parameters using no. of nodes and no. of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of layers\n",
    "layers = 3\n",
    "# no. of nodes in each layer in a list including input and output layers\n",
    "num_nodes = [images.shape[0], 512, 1]\n",
    "num_epochs = 2000\n",
    "\n",
    "# initializing weights according to no. of layers and no. of nodes\n",
    "assert(layers == len(num_nodes))\n",
    "W = {}\n",
    "b = {}\n",
    "Z = {}\n",
    "dw = {}\n",
    "db = {}\n",
    "da = {}\n",
    "dz = {}\n",
    "vdw = {}\n",
    "vdb = {}\n",
    "sdw = {}\n",
    "sdb = {}\n",
    "vdw_corr = {}\n",
    "vdb_corr = {}\n",
    "sdw_corr = {}\n",
    "sdb_corr = {}\n",
    "# Initialize Weights and Momentum \n",
    "for i in range(1, layers):\n",
    "    var_name = str(i)\n",
    "    \n",
    "    # Weight initialization\n",
    "    W[var_name] = torch.empty(num_nodes[i - 1], num_nodes[i])\n",
    "    # Xavier initialization of weights\n",
    "    nn.init.xavier_uniform_(W[var_name], gain=nn.init.calculate_gain('sigmoid'))\n",
    "    b[var_name] = torch.randn(num_nodes[i], 1)\n",
    "    \n",
    "    # Momentum gradient terms initialization\n",
    "    vdw[var_name] = torch.zeros(W[var_name].shape)\n",
    "    vdb[var_name] = torch.zeros(b[var_name].shape)\n",
    "    \n",
    "    # RMSprop terms initialization\n",
    "    sdw[var_name] = torch.zeros(W[var_name].shape)\n",
    "    sdb[var_name] = torch.zeros(b[var_name].shape)\n",
    "    \n",
    "    # Adam terms initialization\n",
    "    vdw_corr[var_name] = torch.zeros(W[var_name].shape)\n",
    "    vdb_corr[var_name] = torch.zeros(b[var_name].shape)\n",
    "    sdw_corr[var_name] = torch.zeros(W[var_name].shape)\n",
    "    sdb_corr[var_name] = torch.zeros(b[var_name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Activation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(A, Y):\n",
    "    loss = (-1 / batch_size) * (torch.matmul(torch.log(A), Y) + torch.matmul(torch.log(1 - A), (1 - Y)))\n",
    "    return loss\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + torch.exp(-x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(x, y):\n",
    "    out = x\n",
    "    for i in range(1, layers):\n",
    "        var_name = str(i)\n",
    "        out = torch.add(torch.matmul(W[var_name].t(), out), b[var_name])\n",
    "        Z[var_name] = out\n",
    "        out = sigmoid(out)\n",
    "        \n",
    "    loss = binary_cross_entropy(out, y)\n",
    "    return loss, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss, out = forward(images, labels)\n",
    "# print(out)\n",
    "# print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward(A, Y, X):\n",
    "    # for last layer\n",
    "    Y = Y.view(1, Y.shape[0])\n",
    "    last_layer = str(layers - 1)\n",
    "    second_last_layer = str(layers - 2)\n",
    "    dz[last_layer] = A - Y\n",
    "    dw[last_layer] = (1 / batch_size) * torch.matmul(dz[last_layer], sigmoid(Z[second_last_layer]).t())\n",
    "    dw[last_layer] = dw[last_layer].t()\n",
    "    db[last_layer] = (1 / batch_size) * torch.sum(dz[last_layer], 1, keepdim = True)\n",
    "    da[second_last_layer] = torch.matmul(W[last_layer], dz[last_layer])\n",
    "    for i in range(layers - 2, 0, -1):\n",
    "        var_name = str(i)\n",
    "        prev_name = str(i - 1)\n",
    "        g_dash_z = sigmoid(Z[var_name]) * (1 - sigmoid(Z[var_name]))\n",
    "        dz[var_name] = da[var_name] * g_dash_z\n",
    "        if i == 1:\n",
    "            dw[var_name] = (1 / batch_size) * torch.matmul(dz[var_name], X.t())\n",
    "        else:\n",
    "            dw[var_name] = (1 / batch_size) * torch.matmul(dz[var_name], sigmoid(Z[prev_name]).t())\n",
    "        dw[var_name] = dw[var_name].t()\n",
    "        db[var_name] = (1 / batch_size) * torch.sum(dz[var_name], 1, keepdim = True)\n",
    "        da[prev_name] = torch.matmul(W[var_name], dz[var_name])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(algo, learning_rate = 1e-3, beta1 = 0, beta2 = 0, epsilon = 1e-8, t = 0):\n",
    "    for i in range(1, layers):\n",
    "        var_name = str(i)\n",
    "        assert(W[var_name].shape == dw[var_name].shape)\n",
    "        assert(b[var_name].shape == db[var_name].shape)\n",
    "        \n",
    "        # RMSProp\n",
    "        if algo == 'rmsprop':\n",
    "            sdw[var_name] = beta2 * sdw[var_name] + (1 - beta2) * (dw[var_name] ** 2)\n",
    "            sdb[var_name] = beta2 * sdb[var_name] + (1 - beta2) * (db[var_name] ** 2)\n",
    "            # Weights update\n",
    "            W[var_name] -= learning_rate * torch.div(dw[var_name], ((sdw[var_name] ** 0.5) + epsilon))\n",
    "            b[var_name] -= learning_rate * torch.div(db[var_name], ((sdb[var_name] ** 0.5) + epsilon))\n",
    "            \n",
    "        elif algo == 'adam':\n",
    "            sdw[var_name] = beta2 * sdw[var_name] + (1 - beta2) * (dw[var_name] ** 2)\n",
    "            sdb[var_name] = beta2 * sdb[var_name] + (1 - beta2) * (db[var_name] ** 2)\n",
    "            vdw[var_name] = beta1 * vdw[var_name] + (1 - beta1) * dw[var_name]\n",
    "            vdb[var_name] = beta1 * vdb[var_name] + (1 - beta1) * db[var_name]\n",
    "            # bias correction\n",
    "            vdw_corr[var_name] = vdw[var_name] / (1 - beta1 ** t)\n",
    "            vdb_corr[var_name] = vdb[var_name] / (1 - beta1 ** t)\n",
    "            sdw_corr[var_name] = sdw[var_name] / (1 - beta2 ** t)\n",
    "            sdb_corr[var_name] = sdb[var_name] / (1 - beta2 ** t)\n",
    "            # Weights update\n",
    "            W[var_name] -= learning_rate * torch.div(vdw_corr[var_name], ((sdw_corr[var_name] ** 0.5) + epsilon))\n",
    "            b[var_name] -= learning_rate * torch.div(vdb_corr[var_name], ((sdb_corr[var_name] ** 0.5) + epsilon))\n",
    "            \n",
    "        # Gradient Descent with Momentum\n",
    "        else:\n",
    "            vdw[var_name] = beta1 * vdw[var_name] + (1 - beta1) * dw[var_name]\n",
    "            vdb[var_name] = beta1 * vdb[var_name] + (1 - beta1) * db[var_name] \n",
    "            # Weights update\n",
    "            W[var_name] -= learning_rate * vdw[var_name]\n",
    "            b[var_name] -= learning_rate * vdb[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [2 / 2000] | TL : 1.0280166864395142 | TA : 50.68359375 | VL : 0.025498089691003162 | VA : 62.5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-aeb90d18b28d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmismatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mupdate_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malgo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepsilon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-3bed3f905e5e>\u001b[0m in \u001b[0;36mupdate_weights\u001b[0;34m(algo, learning_rate, beta1, beta2, epsilon, t)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0malgo\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'adam'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0msdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0msdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mvdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbeta1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mdw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc_list = list()\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "val_acc_list = list()\n",
    "for j in range(1, num_epochs + 1):\n",
    "    if torch.cuda.is_available():\n",
    "        for q in range(1, layers):\n",
    "            var_name = str(q)\n",
    "            W[var_name] = W[var_name].cuda()\n",
    "            b[var_name] = b[var_name].cuda()\n",
    "            vdw[var_name] = vdw[var_name].cuda()\n",
    "            vdb[var_name] = vdb[var_name].cuda()\n",
    "            sdw[var_name] = sdw[var_name].cuda()\n",
    "            sdb[var_name] = sdb[var_name].cuda()\n",
    "        \n",
    "        images, labels = images.cuda(), labels.cuda()\n",
    "    \n",
    "    loss, pred = forward(images, labels)\n",
    "    train_loss = loss.item()\n",
    "    train_loss_list.append(train_loss)\n",
    "    \n",
    "    backward(pred, labels, images)\n",
    "    \n",
    "    pred = (pred >= 0.5)\n",
    "    pred = pred.view(pred.shape[1])\n",
    "    mismatch = torch.sum(torch.eq(pred, labels.byte()))\n",
    "    train_acc = mismatch.item()\n",
    "    \n",
    "    update_weights(algo = 'adam', learning_rate = 1e-5, beta2 = 0.999, epsilon = 1e-8, t = j)\n",
    "\n",
    "    train_acc /= (len(train_loader) * batch_size)\n",
    "    train_acc_list.append(train_acc * 100)\n",
    "    # print('Training accuracy at epoch ', i, ' = ', acc * 100)\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    for batch_idx, (val_images, val_labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            val_images = val_images.cuda()\n",
    "            val_labels = val_labels.cuda()\n",
    "            for q in range(1, layers):\n",
    "                var_name = str(q)\n",
    "                W[var_name] = W[var_name].cuda()\n",
    "                b[var_name] = b[var_name].cuda()\n",
    "            \n",
    "        val_labels = val_labels.float()\n",
    "        val_images = val_images.view(-1, val_images.shape[0]).float()\n",
    "        val_images /= 255\n",
    "\n",
    "        loss, pred = forward(val_images, val_labels)\n",
    "        val_loss += loss.item()\n",
    "        pred = (pred >= 0.5)\n",
    "\n",
    "        pred = pred.view(pred.shape[1])\n",
    "        mismatch = torch.sum(torch.eq(pred, val_labels.byte()))\n",
    "        val_acc += mismatch.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    # print('Validation Loss at epoch ', i, ' = ', val_loss)\n",
    "\n",
    "    val_acc /= (len(test_loader) * 32)\n",
    "    val_acc_list.append(val_acc * 100)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    print(f'Epoch : [{j} / {num_epochs}] | TL : {train_loss} | TA : {train_acc * 100} | VL : {val_loss} | VA : {val_acc * 100}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Loss and Accuracy lists to memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "csvfile = \"train_loss_list_deepnn.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in train_loss_list:\n",
    "        writer.writerow([value])\n",
    "\n",
    "csvfile = \"val_loss_list_deepnn.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in val_loss_list:\n",
    "        writer.writerow([value])\n",
    "\n",
    "csvfile = \"train_acc_list_deepnn.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in train_acc_list:\n",
    "        writer.writerow([value])\n",
    "\n",
    "csvfile = \"val_acc_list_deepnn.csv\"\n",
    "with open(csvfile, \"w\") as output:\n",
    "    writer = csv.writer(output, lineterminator='\\n')\n",
    "    for value in val_acc_list:\n",
    "        writer.writerow([value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Losses and Accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 373
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "with open('train_loss_list_deepnn.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_loss_list2 = list(reader)\n",
    "\n",
    "train_loss_list = list()\n",
    "for i in train_loss_list2:\n",
    "    for j in i:\n",
    "        train_loss_list.append(float(j))\n",
    "        \n",
    "with open('train_acc_list_deepnn.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    train_acc_list2 = list(reader)\n",
    "\n",
    "train_acc_list = list()\n",
    "for i in train_acc_list2:\n",
    "    for j in i:\n",
    "        train_acc_list.append(float(j))\n",
    "        \n",
    "with open('val_loss_list_deepnn.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    val_loss_list2 = list(reader)\n",
    "\n",
    "val_loss_list = list()\n",
    "for i in val_loss_list2:\n",
    "    for j in i:\n",
    "        val_loss_list.append(float(j))\n",
    "        \n",
    "with open('val_acc_list_deepnn.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    val_acc_list2 = list(reader)\n",
    "\n",
    "val_acc_list = list()\n",
    "for i in val_acc_list2:\n",
    "    for j in i:\n",
    "        val_acc_list.append(float(j))\n",
    "\n",
    "iterations = np.arange(0, 2000, 1)\n",
    "plt.plot(iterations, train_loss_list, 'r')\n",
    "# plt.plot(iterations, train_acc_list, 'g')\n",
    "# plt.plot(iterations, val_loss_list, 'b')\n",
    "# plt.plot(iterations, val_acc_list, 'y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mini-Batch Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/home/ivlabs/users/akshay/flowers/train'\n",
    "batch_size = 32\n",
    "tf = transforms.Compose([transforms.Resize((255, 255)),\n",
    "                         transforms.ToTensor(),\n",
    "                        ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = batch_size, shuffle = True, drop_last = True)\n",
    "\n",
    "data_dir = '/home/ivlabs/users/akshay/flowers/test'\n",
    "\n",
    "test_dataset = datasets.ImageFolder(data_dir, transform = tf)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = batch_size, shuffle = True, drop_last = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization of weights, biases and other required variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no. of layers\n",
    "layers = 3\n",
    "# no. of nodes in each layer in a list including input and output layers\n",
    "num_nodes = [255 * 255 * 3, 512, 1]\n",
    "num_epochs = 2000\n",
    "\n",
    "# initializing weights according to no. of layers and no. of nodes\n",
    "assert(layers == len(num_nodes))\n",
    "W = {}\n",
    "b = {}\n",
    "Z = {}\n",
    "dw = {}\n",
    "db = {}\n",
    "da = {}\n",
    "dz = {}\n",
    "vdw = {}\n",
    "vdb = {}\n",
    "sdw = {}\n",
    "sdb = {}\n",
    "# Initialize Weights and Momentum \n",
    "for i in range(1, layers):\n",
    "    var_name = str(i)\n",
    "    \n",
    "    # Weight initialization\n",
    "    W[var_name] = torch.empty(num_nodes[i - 1], num_nodes[i])\n",
    "    # Xavier initialization of weights\n",
    "    nn.init.xavier_uniform_(W[var_name], gain=nn.init.calculate_gain('sigmoid'))\n",
    "    b[var_name] = torch.randn(num_nodes[i], 1)\n",
    "    \n",
    "    # Momentum gradient terms initialization\n",
    "    vdw[var_name] = torch.zeros(W[var_name].shape)\n",
    "    vdb[var_name] = torch.zeros(b[var_name].shape)\n",
    "    \n",
    "    sdw[var_name] = torch.zeros(W[var_name].shape)\n",
    "    sdb[var_name] = torch.zeros(b[var_name].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss and Activation Functions, Forward and Back Propagation, and Weights Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_cross_entropy(A, Y):\n",
    "    loss = (-1 / batch_size) * (torch.matmul(torch.log(A), Y) + torch.matmul(torch.log(1 - A), (1 - Y)))\n",
    "    return loss\n",
    "\n",
    "def sigmoid(x):\n",
    "    return (1 / (1 + torch.exp(-x)))\n",
    "\n",
    "def forward(x, y):\n",
    "    out = x\n",
    "    for i in range(1, layers):\n",
    "        var_name = str(i)\n",
    "        out = torch.add(torch.matmul(W[var_name].t(), out), b[var_name])\n",
    "        Z[var_name] = out\n",
    "        out = sigmoid(out)\n",
    "        \n",
    "    loss = binary_cross_entropy(out, y)\n",
    "    return loss, out\n",
    "\n",
    "def backward(A, Y, X):\n",
    "    # for last layer\n",
    "    Y = Y.view(1, Y.shape[0])\n",
    "    last_layer = str(layers - 1)\n",
    "    second_last_layer = str(layers - 2)\n",
    "    dz[last_layer] = A - Y\n",
    "    dw[last_layer] = (1 / batch_size) * torch.matmul(dz[last_layer], sigmoid(Z[second_last_layer]).t())\n",
    "    dw[last_layer] = dw[last_layer].t()\n",
    "    db[last_layer] = (1 / batch_size) * torch.sum(dz[last_layer], 1, keepdim = True)\n",
    "    da[second_last_layer] = torch.matmul(W[last_layer], dz[last_layer])\n",
    "    for i in range(layers - 2, 0, -1):\n",
    "        var_name = str(i)\n",
    "        prev_name = str(i - 1)\n",
    "        g_dash_z = sigmoid(Z[var_name]) * (1 - sigmoid(Z[var_name]))\n",
    "        dz[var_name] = da[var_name] * g_dash_z\n",
    "        if i == 1:\n",
    "            dw[var_name] = (1 / batch_size) * torch.matmul(dz[var_name], X.t())\n",
    "        else:\n",
    "            dw[var_name] = (1 / batch_size) * torch.matmul(dz[var_name], sigmoid(Z[prev_name]).t())\n",
    "        dw[var_name] = dw[var_name].t()\n",
    "        db[var_name] = (1 / batch_size) * torch.sum(dz[var_name], 1, keepdim = True)\n",
    "        da[prev_name] = torch.matmul(W[var_name], dz[var_name])\n",
    "        \n",
    "def update_weights(algo, learning_rate = 1e-3, beta1 = 0, beta2 = 0, epsilon = 1e-8):\n",
    "    for i in range(1, layers):\n",
    "        var_name = str(i)\n",
    "        assert(W[var_name].shape == dw[var_name].shape)\n",
    "        assert(b[var_name].shape == db[var_name].shape)\n",
    "        \n",
    "        # RMSProp\n",
    "        if algo == 'rmsprop':\n",
    "            sdw[var_name] = beta2 * sdw[var_name] + (1 - beta2) * (dw[var_name] ** 2)\n",
    "            sdb[var_name] = beta2 * sdb[var_name] + (1 - beta2) * (db[var_name] ** 2)\n",
    "            W[var_name] -= learning_rate * torch.div(dw[var_name], ((sdw[var_name] ** 0.5) + epsilon))\n",
    "            b[var_name] -= learning_rate * torch.div(db[var_name], ((sdb[var_name] ** 0.5) + epsilon))\n",
    "        # Gradient Descent with Momentum\n",
    "        else:\n",
    "            vdw[var_name] = beta1 * vdw[var_name] + (1 - beta1) * dw[var_name]\n",
    "            vdb[var_name] = beta1 * vdb[var_name] + (1 - beta1) * db[var_name] \n",
    "            W[var_name] -= learning_rate * vdw[var_name]\n",
    "            b[var_name] -= learning_rate * vdb[var_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : [24 / 2000] | TL : 0.6930381295292877 | TA : 50.43604651162791 | VL : 0.6910189191500345 | VA : 61.458333333333336\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-7f04a2908187>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     99\u001b[0m         \"\"\"\n\u001b[1;32m    100\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    897\u001b[0m         \"\"\"\n\u001b[1;32m    898\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 899\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"P\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/akshay/lib/python3.7/site-packages/PIL/ImageFile.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m                             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m                             \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_code\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m                                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_acc_list = list()\n",
    "train_loss_list = list()\n",
    "val_loss_list = list()\n",
    "val_acc_list = list()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    for q in range(1, layers):\n",
    "        var_name = str(q)\n",
    "        W[var_name] = W[var_name].cuda()\n",
    "        b[var_name] = b[var_name].cuda()\n",
    "        vdw[var_name] = vdw[var_name].cuda()\n",
    "        vdb[var_name] = vdb[var_name].cuda()\n",
    "        sdw[var_name] = sdw[var_name].cuda()\n",
    "        sdb[var_name] = sdb[var_name].cuda()\n",
    "        \n",
    "for j in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    train_acc = 0\n",
    "    for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            \n",
    "        labels = labels.float()\n",
    "        images = images.view(-1, images.shape[0]).float()\n",
    "        images /= 255\n",
    "\n",
    "        loss, pred = forward(images, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        backward(pred, labels, images)\n",
    "\n",
    "        pred = (pred >= 0.5)\n",
    "        pred = pred.view(pred.shape[1])\n",
    "        mismatch = torch.sum(torch.eq(pred, labels.byte()))\n",
    "        train_acc += mismatch.item()\n",
    "        \n",
    "        \n",
    "    \n",
    "    update_weights(algo = 'rmsprop', learning_rate = 1e-6, beta2 = 0.999, epsilon = 1e-8)\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "    train_loss_list.append(train_loss)\n",
    "    train_acc /= (len(train_loader) * batch_size)\n",
    "    train_acc_list.append(train_acc * 100)\n",
    "    # print('Training accuracy at epoch ', i, ' = ', acc * 100)\n",
    "    \n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "    for batch_idx, (val_images, val_labels) in enumerate(test_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            val_images = val_images.cuda()\n",
    "            val_labels = val_labels.cuda()\n",
    "            \n",
    "        val_labels = val_labels.float()\n",
    "        val_images = val_images.view(-1, val_images.shape[0]).float()\n",
    "        val_images /= 255\n",
    "\n",
    "        loss, pred = forward(val_images, val_labels)\n",
    "        val_loss += loss.item()\n",
    "        pred = (pred >= 0.5)\n",
    "\n",
    "        pred = pred.view(pred.shape[1])\n",
    "        mismatch = torch.sum(torch.eq(pred, val_labels.byte()))\n",
    "        val_acc += mismatch.item()\n",
    "\n",
    "    val_loss /= len(test_loader)\n",
    "    val_loss_list.append(val_loss)\n",
    "    # print('Validation Loss at epoch ', i, ' = ', val_loss)\n",
    "\n",
    "    val_acc /= (len(test_loader) * 32)\n",
    "    val_acc_list.append(val_acc * 100)\n",
    "    \n",
    "    clear_output(wait = True)\n",
    "    print(f'Epoch : [{j} / {num_epochs}] | TL : {train_loss} | TA : {train_acc * 100} | VL : {val_loss} | VA : {val_acc * 100}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
